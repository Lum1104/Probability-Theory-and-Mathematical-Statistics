# 《概率论与数理统计》第五章学习报告

## 1 重难点总结

## 1.1 本章小结

人们在长期的实践中认识到**频率具有稳定性**，当试验次数不断增大时，频率稳定在一个数的附近。这一事实显示了可以用一个数来表征事件发生的可能性大小。使得人们认识到**概率是客观存在的**，进而由频率的性质的启发和抽象给出了概率的定义，因而频率的稳定性是概率定义的客观基础。伯努利大数定律则以严密的数学形式论证了频率的稳定性。

中心极限定理表明，在相当一般的情况下，当独立随机变量的个数不断增加时，其和的分布趋于正态分布。这一事实阐明了正态分布的重要性，也揭示了为什么在实际应用中会经常遇到正态分布，解释了产生正态分布变量的源泉，另一方面，它提供了独立同分布随机变量之和$\sum_{k=1}^{n}X_k$(其中X的方差存在)的近似分布，只要加项的个数充分大，就可以不必考虑这个随机变量服从什么分布，都能用正态分布来近似，这在应用中是有效和重要的。

据说中心极限定理之所以叫这个名字，是因为当时这是统计学学者研究的重要问题，“中心问题”

### 1.2 大数定律

#### 1.2.1 弱大数定律（辛钦大数定律）

**定义：**设$X_1, X_2, \cdots$是相互独立，服从同一分布的随机变量序列，且具有数学期望$E(X_k)=\mu(k=1,2,\cdots)$。做前n个变量的算数平均，则对任意的$\epsilon>0$，有
$$
lim_{n\to \infty}P\{|\frac{1}{n}\sum_{k=1}^nX_k-\mu|<\epsilon\} = 1
$$
这个等式表明，等n趋近于无穷时，对于任意的整数ε不等式小于成立的概率很大，通俗的说就是，对于独立同分布且具有均值$\mu$的随机变量，当n很大时他们的算术平均很可能接近于$\mu$

<font color="red">这也是为什么我们经常用很多次实验后的频率来近似表示概率的原因</font>

#### 1.2.2 伯努利大数定律

$$
lim_{n\to \infty}P\{|\frac{f_A}{n}-p|<\epsilon\} = 1
$$

### 1.3 中心极限定理

<font color="red">大量独立、同分布的随机变量之和的极限分布是正态分布</font>

**定义：**设$X_1, X_2, \cdots$是相互独立，服从同一分布的随机变量序列，且具有数学期望$E(X_k)=\mu,D(X)=\sigma^2>0$，则随机变量之和的标准化变量的分布函数对任意x满足
$$
Y_n = \frac{\sum_{k=1}^nX_k-E(\sum_{k=1}^nX_k)}{\sqrt{D(\sum_{k=1}^nX_k)}}=\frac{\sum_{k=1}^nX_k-n\mu}{\sqrt{n}\sigma}
$$
即当n充分大时：
$$
\frac{\sum_{k=1}^nX_k-n\mu}{\sqrt{n}\sigma}\text{近似服从标准正态分布}
$$
例子：

- 一个城市的耗电量是大量用户耗电量的总和
- 以物理实验的测量误差

### 1.4 重要概念

**依概率收敛、伯努利大数定律、辛钦大数定律、独立同分布的中心极限定理、李雅普诺夫中心极限定理**

## 2 学习中的思考、心得

大数定律：解释了为什么能用大量实验下的频率近似的表示概率

中心极限定理：解释了为什么世界上很多现象都服从正态分布

## 3 跨学科应用

在数学建模中，当收集到的数据在某些样本出现缺失值时，在一定的情况下，可以根据中心极限定理来对缺失值进行填补，例如下图就是一个实际项目中某一特征的例子，可以很明显的看出，这个特征是服从正态分布的。

![](D:\SZTU\大二\Python\python大作业\16.png)